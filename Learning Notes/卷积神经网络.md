

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

* [卷积神经网络（Convolution Neural Network,CNN）](#卷积神经网络convolution-neural-networkcnn)
	* [基础概念](#基础概念)
		* [卷积层](#卷积层)
			* [通道（channel）](#通道channel)
			* [填充（padding）](#填充padding)
			* [步长（stride）](#步长stride)
			* [卷积的计算](#卷积的计算)
		* [池化（pooling）](#池化pooling)
			* [最大池化（max pooling）](#最大池化max-pooling)
			* [平均池化（average pooling）](#平均池化average-pooling)
		* [全连接（Full connect,FC）](#全连接full-connectfc)
		* [SoftMax](#softmax)
			* [Softmax VS k个二元分类器](#softmax-vs-k个二元分类器)
			* [Softmax 与 SVM](#softmax-与-svm)
		* [激活函数（Activate Function）](#激活函数activate-function)
			* [激活函数的作用](#激活函数的作用)
			* [激活函数的选择](#激活函数的选择)
		* [标准化（normalization）](#标准化normalization)
			* [批标准化（batch normalization）](#批标准化batch-normalization)
		* [下采样](#下采样)
		* [上采样](#上采样)
		* [反卷积](#反卷积)
		* [感受野（Receptive field，RF）](#感受野receptive-fieldrf)
			* [感受野可视化](#感受野可视化)
			* [感受野的计算](#感受野的计算)
		* [局部连接与权值共享](#局部连接与权值共享)
			* [局部连接（Local Connectivity）](#局部连接local-connectivity)
			* [权值共享（parameter sharing）](#权值共享parameter-sharing)
	* [经典CNN模型](#经典cnn模型)
		* [总览](#总览)
		* [LeNet](#lenet)
		* [AlexNet](#alexnet)
		* [ZFNet](#zfnet)
		* [GoogleNet-inception](#googlenet-inception)
		* [VGG](#vgg)
		* [ResNet](#resnet)
		* [DenseNet](#densenet)
		* [其他的CNN网络模型](#其他的cnn网络模型)
	* [注意事项](#注意事项)

<!-- /code_chunk_output -->






# 卷积神经网络（Convolution Neural Network,CNN）

    性质：位移、尺度、缩放、非线性形变稳定性

卷积神经网络（CNN）是一类人工神经网络。因此，它们是由被称为「神经元」的单元构成的，这些单元可根据输入的加权和输出一个活动水平。这个活动水平通常是输入的非线性函数，通常只是一个整流线性单元（ReLU），其中当输入全为正时活动等于输入，当输入全为非正时活动等于 0。

CNN 的独特之处是神经元之间的连接的构建方式。在一个前馈神经网络中，单元会被组织成层的形式，给定层的单元只会获得来自其下面一层的输入（即不会有来自同一层或后续层的其它单元的输入，大多数情况下也不会有来自之前超过 1 层的输入）。CNN 是**前馈网络**。但不同于标准的单纯的前馈网络，CNN 中的单元具有一种空间排列。在每一层，单元都会被组织成 2D 网格形式，这被称为特征图（feature map）。每一个特征图都是在其下面一层上执行卷积所得的结果（CNN 也因此得名）。这意味着在其下面一层的每个位置都应用了同样的卷积过滤器（权重集）。因此，在该 2D 网格上特定位置的单元只能收到来自其下面一层相似位置的单元的输入。此外，输入上附带的权重对一个特征图中的每个单元都是一样的（而各个特征图各不相同）。
<div align="center">
<img src=CNN_stuffs/CNN-1.jpg alt=CNN>  

Convolution Neural Network
</div>


大多数现代 CNN 都有多个（至少 5）这样的层，其中最后一层会向一个全连接层馈送数据。全连接层就像是标准的前馈网络，其中没有空间布局或受限的连接。通常会有 2-3 个全连接层连在一起使用，并且网络的最后一层执行分类。举个例子，如果该网络执行的是 10 类目标分类，那么最后一层将会有 10 个单元，会有一个 softmax 操作应用在它们的活动水平上以得到每个类别相关的概率。

这些网络主要通过监督学习和反向传播训练。这时，提供给网络的输入是图像及其相关类别标签构成的配对集。图像像素值输入网络的第一层，然后网络最后一层得出一个预测类别。如果这个预测得到的标签与所提供的标签不一致，那么就会计算梯度，确定应该如何修改权重（即卷积过滤器中的值）以使分类正确。如此重复很多很多次（很多网络都是在 ImageNet 数据库上训练的，这个数据库包含 1000 个目标类别的超过 100 万张图像），就能得到在留存测试图像上有很高准确度的模型。CNN 的某些变体模型现在已能达到 4.94% 乃至更低的错误率，优于人类水平。要得到优良的表现，通常需要很多训练「技巧」，比如智能学习率选择和权重正则化（主要是通过 dropout，即在每个训练阶段都有随机一半的权重关闭）。

历史上曾使用无监督预训练来初始化权重，然后再使用监督学习来进行改善。但是，这似乎已经不再是优越性能所必需的了。

*参考：* [卷积神经网络十五问](http://baijiahao.baidu.com/s?id=1602962974655940776&wfr=spider&for=pc)；[卷积神经网络超详细介绍](https://blog.csdn.net/jiaoyangwm/article/details/80011656#1_2)

## 基础概念

### 卷积层
这一层就是卷积神经网络最重要的一个层次，也是“卷积神经网络”的名字来源。在这个卷积层，有两个关键操作：
- 局部关联。每个神经元看做一个滤波器(filter)
- 窗口(receptive field)滑动， filter对局部数据计算
  
卷积层超参数有：
- 通道（channel）
- 填充（padding）：P
- 步长（stride）： S

参考：[卷积神经网络CNN总结](https://www.cnblogs.com/skyfsm/p/6790245.html)

#### 通道（channel）
通道也叫做深度（depth），输入与输出都有自己的通道数目，输入通道的数目决定每个filter里面有多少个卷积核，输出通道的数目由超参数$out channel$决定，也就是有多少个神经元/filter，经过一次卷积之后，便会得到相应通道数的卷积输出
<div align="center">
<img src=CNN_stuffs/channel.png alt=channel>
</div>

#### 填充（padding）

使用filter来做元素乘法运算来完成卷积运算的。目的是为了完成探测垂直边缘这种特征。但这样做会带来两个问题。

- 卷积运算后，输出图片尺寸缩小
- 越是边缘的像素点，对于输出的影响越小，因为卷积运算在移动的时候到边缘就结束了。中间的像素点有可能会参与多次计算，但是边缘像素点可能只参与一次。所以我们的结果可能会丢失边缘信息。

为了解决这个问题，引入padding，在图片外围补充一些像素点，把这些像素点初始化为0：
<div align="center">
<img src=CNN_stuffs/padding.png alt=pad>
</div>

#### 步长（stride）
Stride表示filter在原图片中水平方向和垂直方向每次的步进长度。若stride=2，则表示filter每次步进长度为2，即隔一点移动一次。
<div align="center">
<img src=CNN_stuffs/stride.png alt=stride>
</div>

####卷积的计算
一个$padding=1,stride=2,kernel size=3x3, filter number=2$的卷积操作如下所示
<div align="center">
<img src=CNN_stuffs/conv.gif alt=conv>
</div>
蓝色的矩阵(输入图像)对粉色的矩阵（filter）进行矩阵内积计算并将三个内积运算的结果与偏置值b相加（比如下图的计算：2+（-2+1-2）+（1-2-2） + 1= 2 - 3 - 3 + 1 = -3），计算后的值就是绿框矩阵的一个元素。
<div align="center">
<img src=CNN_stuffs/conv_cal.jpg alt=cal>
</div>


### 池化（pooling）

池化的作用：
- 减少参数。通过对 Feature Map 降维，使特征图变小，有效减少后续层需要的参数，简化网络计算复杂度，并通过减小网络参数和计算量来抑制过拟合
- Translation Invariance。它表示对于 Input，当其中像素在邻域发生微小位移时，Pooling Layer 的输出是不变的。这就使网络的鲁棒性增强了，有一定抗扰动的作用
- 进行特征压缩，提取主要特征，即特征降维，我们知道一幅图像含有的信息是很大的，特征也很多，但是有些信息对于我们做图像任务时没有太多用途或者有重复，我们可以把这类冗余信息去除，把最重要的特征抽取出来，这也是池化操作的一大作用。
- 特征不变性，也就是我们在图像处理中经常提到的特征的尺度不变性，池化操作就是图像的resize，平时一张狗的图像被缩小了一倍我们还能认出这是一张狗的照片，这说明这张图像中仍保留着狗最重要的特征，我们一看就能判断图像中画的是一只狗，图像压缩时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。


pooling操作是特征图缩小，有可能影响网络的准确度，因此可以通过增加特征图的深度来弥补（深度变为原来的2倍）。

根据相关理论，特征提取的误差主要来自两个方面：
- 邻域大小受限造成的估计值方差增大；
- 卷积层参数误差造成估计均值的偏移。

一般来说，
- mean-pooling能减小第一种误差（邻域大小受限造成的估计值方差增大），更多的保留图像的背景信息，
- max-pooling能减小第二种误差（卷积层参数误差造成估计均值的偏移），更多的保留纹理信息。
- Stochastic-pooling则介于两者之间，通过对像素点按照数值大小赋予概率，再按照概率进行亚采样，在平均意义上，与mean-pooling近似，在局部意义上，则服从max-pooling的准则。
#### 最大池化（max pooling）
即对一小块区域取最大值,假设pooling的窗大小是2x2,

1.forward:就是在前面卷积层的输出的不重叠地进行2x2的取最大值降采样，就得到max-pooling的值。
<div align="center">
<img src=CNN_stuffs/max_pooling.png alt=maxp>
</div>

2.backward:在max-pooling前向传播时,只取最大值,其他值无作用。因此反向传播时，只关注最大值，所以将残差传递到该最大值的位置，区域内其他2*2-1=3个位置置零

<div align="center">
<img src=CNN_stuffs/max_pooling_backward.png alt=maxpb>
</div>



#### 平均池化（average pooling）
假设pooling的窗大小是2x2, 在forward的时候啊，就是在前面卷积完的输出上依次不重合的取2x2的窗平均，得到一个值就是当前mean pooling之后的值，对一块小区域取平均值,假设pooling的窗大小是2x2,

1.forward:就是在前面卷积层的输出的不重叠地进行2x2的取平均值降采样，就得到mean-pooling的值。

<div align="center">
<img src=CNN_stuffs/mean_pooling.png alt=meanp>
</div>

2.backward:把一个值分成四等分放到前面2x2的格子区域里面就好了。
<div align="center">
<img src=CNN_stuffs/mean_pooling_backward.png alt=meanpb>
</div>

### 全连接（Full connect,FC）

两层之间所有神经元都有权重连接，通常全连接层在卷积神经网络尾部。也就是跟传统的神经网络神经元的连接方式是一样的：

<div align="center">
<img src=CNN_stuffs/fc.png alt=fc>
</div>

作用：
- 将前面经过多次卷积后高度抽象化的特征进行整合，然后可以进行归一化，对各种分类情况都输出一个概率，之后的分类器(Classifier)可以根据全连接得到的概率进行分类。 

缺点：
- 参数过多，过多使用全连接层将导致计算复杂度大大增加
- 会破坏图像的空间结构

### SoftMax
在机器学习尤其是深度学习中，softmax是个非常常用而且比较重要的函数，尤其在多分类的场景中使用广泛。他把一些输入映射为0-1之间的实数，并且归一化保证和为1，因此多分类的概率之和也刚好为1。 
首先我们简单来看看softmax是什么意思。顾名思义，softmax由两个单词组成，其中一个是max。对于max我们都很熟悉，比如有两个变量a,b。如果a>b，则max为a，反之为b。用伪码简单描述一下就是 if a > b return a; else b。 
另外一个单词为soft。max存在的一个问题是什么呢？如果将max看成一个分类问题，就是非黑即白，最后的输出是一个确定的变量。更多的时候，我们希望输出的是取到某个分类的概率，或者说，我们希望分值大的那一项被经常取到，而分值较小的那一项也有一定的概率偶尔被取到，所以我们就应用到了soft的概念，即最后的输出是每个分类被取到的概率。

假设有一个数组V，Vi表示V中的第i个元素，那么这个元素的softmax值为: 
$$S_i = \frac{e^i}{\sum_j e^j}$$
该元素的softmax值，就是该元素的指数与所有元素指数和的比值，softmax设计的初衷，是希望特征对概率的影响是乘性的。 
<div align="center">
<img src=CNN_stuffs/softmax.png alt=sfmax>
</div>

#### Softmax VS k个二元分类器
如果你在开发一个音乐分类的应用，需要对k种类型的音乐进行识别，那么是选择使用 softmax 分类器呢，还是使用 logistic 回归算法建立 k 个独立的二元分类器呢？ 
这一选择取决于你的类别之间是否互斥，例如，如果你有四个类别的音乐，分别为：古典音乐、乡村音乐、摇滚乐和爵士乐，那么你可以假设每个训练样本只会被打上一个标签（即：一首歌只能属于这四种音乐类型的其中一种），此时你应该使用类别数 k = 4 的softmax回归。（如果在你的数据集中，有的歌曲不属于以上四类的其中任何一类，那么你可以添加一个“其他类”，并将类别数 k 设为5。） 
如果你的四个类别如下：人声音乐、舞曲、影视原声、流行歌曲，那么这些类别之间并不是互斥的。例如：一首歌曲可以来源于影视原声，同时也包含人声 。这种情况下，使用4个二分类的 logistic 回归分类器更为合适。这样，对于每个新的音乐作品 ，我们的算法可以分别判断它是否属于各个类别。

#### Softmax 与 SVM
Softmax线性分类器的损失函数计算相对概率，又称交叉熵损失「Cross Entropy Loss」。线性 SVM 分类器和 Softmax 线性分类器的主要区别在于损失函数不同。SVM 使用 hinge loss，更关注分类正确样本和错误样本之间的距离「Δ = 1」，只要距离大于 Δ，就不在乎到底距离相差多少，忽略细节。而 Softmax 中每个类别的得分函数都会影响其损失函数的大小。举个例子来说明，类别个数 C = 3，两个样本的得分函数分别为[10, -10, -10]，[10, 9, 9]，真实标签为第0类。对于 SVM 来说，这两个 Li 都为0；但对于Softmax来说，这两个 Li 分别为0.00和0.55，差别很大。


### 激活函数（Activate Function）
	增加模型的非线性表达能力

神经网络神经元中，输入的 inputs 通过加权，求和后，还被作用了一个函数，这个函数就是激活函数 Activation Function。
<div align="center">
<img src=CNN_stuffs/activate1.png alt=sfmax>
</div>

#### 激活函数的作用
神经网络中激活函数的主要作用是提供网络的非线性建模能力，如不特别说明，激活函数一般而言是非线性函数。假设一个示例神经网络中仅包含线性卷积和全连接运算，那么该网络仅能够表达线性映射，即便增加网络的深度也依旧还是线性映射，难以有效建模实际环境中非线性分布的数据。加入（非线性）激活函数之后，深度神经网络才具备了分层的非线性映射学习能力。

激活函数通常有如下一些性质：

- 非线性：如果不用激励函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合。如果使用的话，激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中。当激活函数是非线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。但是，如果激活函数是恒等激活函数的时候（即），就不满足这个性质了，而且如果MLP使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的。
- 可微性： 当优化方法是基于梯度的时候，这个性质是必须的。
- 单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。
- 随机小值初始化： 当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要很用心的去设置初始值。
- 输出值的范围： 当激活函数输出值是 有限 的时候，基于梯度的优化方法会更加 稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是 无限 的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate。

#### 激活函数的选择
常用的激活函数：
<div align="center">
<img src=CNN_stuffs/activate.png alt=af>
</div>


- sigmoid:
  - 优点：
    - 在特征相差比较复杂或是相差不是特别大时效果比较好（这样饱不饱和就没那么在影响了？）。
	- sigmoid激活函数在除了前馈网络以外的情景中更为常见。循环网络、许多概率模型以及一些自编码器有一些额外的要求使得它们不能使用分段线性激活函数，并且使得sigmoid单元更具有吸引力，尽管它存在饱和性的问题。
  - 缺点：
    - 激活函数计算量大，反向传播求误差梯度时，求导涉及除法；
    - 与分段线性单元不同，sigmoid单元在其大部分定义域内都饱和——当z取绝对值很大的正值时，它们饱和到一个高值，当z取绝对值很大的负值时，它们饱和到一个低值，并且仅仅当z接近0时它们才对输入强烈敏感。sigmoid单元的广泛饱和性会使得基于梯度的学习变得非常困难。因为这个原因，现在不鼓励将它们用作前馈网络中的隐藏单元。当使用一个合适的代价函数来抵消sigmoid的饱和性时，它们作为输出单元可以与基于梯度的学习相兼容。
    - Sigmoid 的 output 不是0均值。
- ReLU:
  - 优点
    - 速度快    和sigmoid函数需要计算指数和倒数相比，relu函数其实就是一个max(0,x)，计算代价小很多。
    - 减轻梯度消失问题    回忆一下计算梯度的公式。其中，是sigmoid函数的导数。在使用反向传播算法进行梯度计算时，每经过一层sigmoid神经元，梯度就要乘上一个。从下图可以看出，函数最大值是1/4。因此，乘一个会导致梯度越来越小，这对于深层网络的训练是个很大的问题。而relu函数的导数是1，不会导致梯度变小。当然，激活函数仅仅是导致梯度减小的一个因素，但无论如何在这方面relu的表现强于sigmoid。使用relu激活函数可以让你训练更深的网络。
    - 稀疏性    通过对大脑的研究发现，大脑在工作的时候只有大约5%的神经元是激活的，而采用sigmoid激活函数的人工神经网络，其激活率大约是50%。有论文声称人工神经网络在15%-30%的激活率时是比较理想的。因为relu函数在输入小于0时是完全不激活的，因此可以获得一个更低的激活率。
  - 缺点：
    - 训练的时候很”脆弱”，很容易就”die”了


### 标准化（normalization）
#### 批标准化（batch normalization）


### 下采样
### 上采样

### 反卷积



### 感受野（Receptive field，RF）

    感受野 指的是一个特定的CNN特征（特征图上的某个点）在输入空间所受影响的区域。
    一个感受野可以用中心位置(center location)和大小(size)来表征。

某一层的卷积核大小对应于在上一层输出的“图像”上的“视野”大小。比如，某层有 3x3 的卷积核，那就是一个 3x3 大小的滑动窗口在该层的输入“图像”上去扫描，我们就可以谈相对于上一层，说该层下特征图（feature map）当中任一特征点（feature）的“感受野”大小只有 3x3（打引号说明术语引用不够严谨）。

对于一个CNN特征来说，感受野中的每个像素值（pixel）并不是同等重要。一个像素点越接近感受野中心，它对输出特征的计算所起作用越大。这意味着某一个特征不仅仅是受限在输入图片中某个特定的区域（感受野），并且呈指数级聚焦在区域的中心。

#### 感受野可视化
假定我们所考虑的 CNN 架构是对称的，并且输入图像也是方形的。这样的话，我们就忽略掉不同长宽所造成的维度不同。

Way1 对应为通常的一种理解感受野的方式。在下方左侧的上图中，是在 5x5 的图像(蓝色)上做一个 3x3 卷积核的卷积计算操作，步长为2，padding 为1，所以输出为 3x3 的特征图(绿色)。那么该特征图上的每个特征(1x1)对应的感受野，就是 3x3。在下方左侧的下图中，是在上述基础上再加了一个完全一样的卷积层。对于经过第二层卷积后其上的一个特征(如红色圈)在上一层特征图上“感受”到 3x3 大小，该 3x3 大小的每个特征再映射回到图像上，就会发现由 7x7 个像素点与之关联，有所贡献。于是，就可以说第二层卷积后的特征其感受野大小是 7x7（需要自己画个图，好好数一数）。Way2 （下方右侧的图像）是另一种理解的方式，主要的区别仅仅是将两层特征图上的特征不进行“合成”，而是保留其在前一层因“步长”而产生的影响。
<div align="center">
<img src=CNN_stuffs\RF-1.png alt=RF1>
</div>
Way2 的理解方式其实更具有一般性，我们可以无需考虑输入图像的大小对感受野进行计算。如下图：
<div align="center">
<img src=CNN_stuffs\RF-2.png alt=RF2>
</div>
虽然，图上绘制了输入 9x9 的图像（蓝色），但是它的大小情况是无关紧要的，因为我们现在只关注某“无限”大小图像某一像素点为中心的一块区域进行卷积操作。首先，经过一个 3x3 的卷积层（padding=1，stride=2）后，可以得到特征输出（深绿色）部分。其中深绿色的特征分别表示卷积核扫过输入图像时，卷积核中心点所在的相对位置。此时，每个深绿色特征的感受野是 3x3 （浅绿）。这很好理解，每一个绿色特征值的贡献来源是其周围一个 3x3 面积。再叠加一个 3x3 的卷积层（padding=1，stride=2）后，输出得到 3x3 的特征输出（橙色）。此时的中心点的感受野所对应的是黄色区域 7x7，代表的是输入图像在中心点橙色特征所做的贡献。

    也就是说两层 3x3 的卷积层直接堆叠后（无池化）可以算的有感受野是 5x5，三层堆叠后的感受野就是 7x7。

#### 感受野的计算
为了计算CNN每一层的感受野，除了要知道特征图每个维度的特征数$n$，还需要记录每一层的其他信息，这包括当前层的感受野大小$r$，两个相邻特征的距离（跳跃的距离，如前面可视化所示）$j$，和左上角特征（第一个特征）的中心坐标$start$。注意感受野（其实是特征图第一个特征的感受野）的中心坐标就等于这个特征的中心坐标，就如前面可视化中所示。当采用的卷积其核大小为$k$，$padding$大小为$p$，步长为$s$，输出特征图的感受野可以按照如下公式计算：
$$\begin{aligned}
    n_{out}&=\left[\frac{n_{in}+2p-k}{s}\right]+1\\
    j_{out}&=j_{in}\times s\\
    r_{out}&=r_{in}+\left(k-1\right)\times j_{in}\\
    start_{out}&=start_{in}+\left(\frac{k-1}{2}-p\right)\times j_{in}
\end{aligned}$$
- 第一个式子根据输入特征图大小以及卷积参数计算输出特征图大小;
- 第二个式子计算输出特征图的特征间的间隔j，其等于上一层的间隔值乘以卷积的步长，所以间隔值将是按照步长呈指数级增长;
- 第三个式子计算输出特征图的感受野大小，其等于前一层感受野大小加上$(k−1)∗j_{in}$，所以感受野是呈指数级增加，并且还有一个因子$k−1$;
- 第四个式子计算输出特征图的第一个特征感受野的中心坐标，其等于第一层的中心坐标加上$(k−1)/2∗j_{in}$，再减去$p∗j_{in}$，注意两项都要乘以前一层的间隔距离以得到实际距离。
<div align="center">
<img src=CNN_stuffs\RF-3.png alt=RF3>
</div>
上图中除了公式和说明部分外，有两行分别代表的是第一层卷积和第二层卷积。在每行中，应从左往右观察卷积核计算和操作。

第一层比较简单，最后输出 3x3 绿色的特征图，每个特征有阴影框大小来表示每个特征对应的感受野大小 3x3。其中$start_1$表示的 0.5 几何半径，我已经用红色标识出来，对应于阴影面积覆盖到的绿色面积的几何半径。

第二层，由于有一个单位的 padding，所以 3x3 卷积核是按照蓝色箭头标记作为的起始方向开始，在所有的绿色位置上挪动的。最后算得特征的感受野大小为 7x7，亦对应于阴影框和阴影区域部分。其中$start_2$是 0.5 也已经用红色标记了出来。

对于感受野大小的计算，另外有一个博客（[Calculating Receptive Field of CNN](http://shawnleezx.github.io/blog/2017/02/11/calculating-receptive-field-of-cnn/)）给出一个更简洁的计算公式，对于第k层的感受野大小计算如下： 

$$l_k = l_{k-1} + ((f_k - 1) * \prod_{i=1}^{k-1}s_i)$$

其中$l_k−1$是第$k−1$层的感受野大小，而$f_k$是当前层的卷积核大小，$s_i$是第$i$层的步长。从这个公式可以看到，相比前一层，当前层的感受野大小在两层之间增加了$(f_k - 1) * \prod_{i=1}^{k-1}s_i$ ，如果$stride$大于1的话，这是一个指数级增加。这个公式也可以这样理解，对于第 $k$ 层，其卷积核为 $f_k$，那么相比前一层需要计算 $f_k$ 个位置（或者神经元，意思是 k 层的一个位置在 $k−1$ 层的视野大小是 $f_k$ ），但是这些位置要一直向前扩展到输入层。对于第一个位置，扩展后的感受野为 $l_k−1$ ，正好是前一层的感受野大小，但是对于剩余的 $f_k−1$ 个位置就要看stride大小，你需要扩展到前面所有层的$stride$（注意不包括当前层的$stride$，当前层的$stride$只会影响后面层的感受野），所以需要乘以 $\prod_{i=1}^{k-1}s_i$ ，这样剩余 $f_k−1$ 个位置的感受野大小就是 $(f_k - 1) * \prod_{i=1}^{k-1}s_i$ ，和第一个位置的感受野加到一起就是上面的公式了。。其实这个公式算是整合了前面的公式2和公式3（第一层的$j=1$），两个本质上是一致的，不过如果你仅想计算感受野大小可以用这个公式更方便。

参考：[关于感受野 (Receptive field) 你该知道的事](https://iphysresearch.github.io/posts/receptive_field.html)； [你知道如何计算CNN感受野吗？这里有一份详细指南](https://blog.csdn.net/xiaohu2022/article/details/80647180)
### 局部连接与权值共享

    也被称为稀疏连接和参数共享
####局部连接（Local Connectivity）
局部连接,就是卷积层的节点仅仅和其前一层的部分节点相连接，只用来学习局部特征。局部感知结构的构思理念来源于动物视觉的皮层结构，其指的是动物视觉的神经元在感知外界物体的过程中起作用的只有一部分神经元。在计算机视觉中，图像中的某一块区域中，像素之间的相关性与像素之间的距离同样相关，距离较近的像素间相关性强，距离较远则相关性就比较弱，由此可见局部相关性理论也适用于计算机视觉的图像处理领域。因此，局部感知采用部分神经元接受图像信息，再通过综合全部的图像信息达到增强图像信息的目的。从下图中我们可以看到，第n+1层的每个节点只与第n层的3个节点相连接，而非与前一层全部5个神经元节点相连，这样原本需要5x3=15个权值参数，现在只需要3x3=9个权值参数，减少了40%的参数量，同样，第n+2层与第n+1层之间也用同样的连接方式。这种局部连接的方式大幅减少了参数数量，加快了学习速率，同时也在一定程度上减少了过拟合的可能。
<div align="center">
<img src=CNN_stuffs\local_conn.png alt=locn>
</div>

#### 权值共享（parameter sharing）

在卷积层中每个神经元连接数据窗的权重是固定的，每个神经元只关注一个特性。神经元就是图像处理中的滤波器，比如边缘检测专用的Sobel滤波器，即卷积层的每个滤波器都会有自己所关注一个图像特征，比如垂直边缘，水平边缘，颜色，纹理等等，这些所有神经元加起来就好比就是整张图像的特征提取器集合

所谓权值共享就是说给定一张输入图片，用一个卷积核来卷积这张图，**卷积核里的值叫做权重**，这张图的每个位置是被同一个卷积核扫的，即卷积的时候所用的权重是一样的。其实权值共享这个词说全了就是整张图片在使用同一个卷积核内的参数，比如一个3x3x1的卷积核，这个卷积核内9个的参数被整张图共享，而不会因为图像内位置的不同而改变卷积核内的权系数。说的再直白一些，就是用一个卷积核不改变其内权系数的情况下卷积处理整张图片（当然CNN中每一层不会只有一个卷积核的，这样说只是为了方便解释而已）。

把局部连接中的每一个卷积核（感受野）对应的权值进行共享，就可以进一步减少网络中参数的个数，即下一层每一个像素点是由上一层对应位置的对应位置的F×F的局部区域图片与同一卷积核F×F的权值做内积，加偏重后再经过非线性映射而来的，至此，网络训练参数的数量不再受原始输入图片大小的影响。此处需要注意，一组卷积核F×F的权值只能得到一张Feature map,为更好的表示图像特征，需要使用不同的多组卷积核（过滤器）来使学得的图像特征更丰富。

每个层有多个Feature Map，每个Feature Map通过一种卷积滤波器提取输入的一种特征，然后每个Feature Map有多个神经元，即卷积层的每个滤波器都会有自己所关注一个图像特征，比如垂直边缘，水平边缘，颜色，纹理等等，这些所有神经元加起来就好比就是整张图像的特征提取器集合。
<div align="center">
<img src=CNN_stuffs\filter.png alt=filter>
</div>
请注意，有时参数共享假设可能没有意义。当ConvNet的输入图像具有某些特定的中心结构时尤其如此，例如，当我们期望应该在图像的一侧学习完全不同的特征而不是另一侧。一个实际示例是当输入是已经在图像中居中的面部时。你可能期望在不同的空间位置可以（并且应该）学习不同的眼睛特定或头发特定的特征。在这种情况下，通常放松参数共享方案，并且简单地将该层称为局部连接层。


## 经典CNN模型
### 总览
| 模型名称 | 发布时间 | 特性  | 其他  |
| :------: | :------: | :---: | :---: |
|          |          |       |       |
### LeNet
### AlexNet
### ZFNet
### GoogleNet-inception
### VGG
### ResNet
### DenseNet
### 其他的CNN网络模型

不断更新中[其他网络模型](special_CNNs.md)

## 注意事项